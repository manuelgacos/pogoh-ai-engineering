{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34c61996",
   "metadata": {},
   "source": [
    "# Initial data cleaning\n",
    "\n",
    "In this notebook we do some data cleaning for a small portion of the POGOH dataset, this will give some ideas on how to proceed for dealing with the data at a larger scale.\n",
    "\n",
    "__NOTE:__ In this dataset there were some NaN observations in End Station Id and End Station Name, and because of this the ID column is read as a float instead of integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a7ecebcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47523 entries, 0 to 47522\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   Closed Status       47523 non-null  object        \n",
      " 1   Duration            47523 non-null  int64         \n",
      " 2   Start Station Id    47523 non-null  int64         \n",
      " 3   Start Date          47523 non-null  datetime64[ns]\n",
      " 4   Start Station Name  47523 non-null  object        \n",
      " 5   End Date            47523 non-null  datetime64[ns]\n",
      " 6   End Station Id      47497 non-null  float64       \n",
      " 7   End Station Name    47497 non-null  object        \n",
      " 8   Rider Type          47523 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(1), int64(2), object(4)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"/home/manuel/Documents/AI/pogoh-ai-engineering/data/raw/april-2025.xlsx\"\n",
    "\n",
    "# Load the Excel file into a DataFrame\n",
    "pogoh_df = pd.read_excel(file_path)\n",
    "pogoh_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770e7912",
   "metadata": {},
   "source": [
    "I noticed that the names of some columns in the dataset have spaces, which might be easy for reading but while using the data for training models might lead to unexpected behavior. For this reason, I decided to convert them to lower case and convert the spaces to underscores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f322d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize column names: lowercase, replace spaces with underscores\n",
    "pogoh_df.columns = (\n",
    "    pogoh_df.columns.str.strip()          # remove leading/trailing spaces\n",
    "                     .str.lower()         # convert to lowercase\n",
    "                     .str.replace(\" \", \"_\")  # replace spaces with underscores\n",
    ")\n",
    "pogoh_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6765f580",
   "metadata": {},
   "source": [
    "There are several tasks that could be done for data cleaning, so I'll divide them by broad categories.\n",
    "\n",
    "## Missing & Invalid Data\n",
    "\n",
    "- Inspect and handle rows with missing End Station Id and End Station Name.\n",
    "- Drop or repair rows with Duration <= 0 or End Date < Start Date.\n",
    "- Recalculate duration from timestamps and check against Duration column.\n",
    "\n",
    "### Missing Stations\n",
    "\n",
    "We start by handling trips where either the start station or the end station is missing. In this particular set there were no trips where the starting station information is missing, which makes sense since retrieving the bike from a stations is what initializes a trip. However, this information could still be missing due to some unforseen errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfe33cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where either Start Station Id or Start Station Name is missing\n",
    "missing_start_station = pogoh_df[\n",
    "    pogoh_df[\"start_station_id\"].isnull() | pogoh_df[\"start_station_name\"].isnull()\n",
    "]\n",
    "\n",
    "# Count how many of these rows fall into each Closed Status category\n",
    "missing_start_status_counts = missing_start_station[\"closed_status\"].value_counts()\n",
    "print(missing_start_status_counts)\n",
    "\n",
    "# Preview the first few rows with missing values\n",
    "missing_start_status_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886d6325",
   "metadata": {},
   "source": [
    "Regarding trips with missing information from the end station, there were 26 trips missing both the end station ID and name. All of them had the closed status terminated.\n",
    "IN the case where only one were missing inputing information would be possible by matching the ID or the station name correspondingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7072860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where either End Station Id or End Station Name is missing\n",
    "missing_end_station = pogoh_df[\n",
    "    pogoh_df[\"end_station_id\"].isnull() | pogoh_df[\"end_station_name\"].isnull()\n",
    "]\n",
    "\n",
    "print(\"=== Missing End Station ID ===\")\n",
    "print(sum(pogoh_df[\"end_station_id\"].isnull()))\n",
    "print(\"\\n=== Missing End Station Name ===\")\n",
    "print(sum(pogoh_df[\"end_station_name\"].isnull()))\n",
    "missing_end_station.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94caeff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many of these rows fall into each Closed Status category\n",
    "missing_end_status_counts = missing_end_station[\"closed_status\"].value_counts()\n",
    "print(missing_end_status_counts)\n",
    "\n",
    "# Preview the first few rows with missing values\n",
    "missing_end_station.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07ed6e0",
   "metadata": {},
   "source": [
    "The treatment of these kind of trips could be done for an anomaly detection framework. For now, I'll be dropping any trips that might exhibit this behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49613f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows with missing end station ID or name\n",
    "pogoh_df_cleaned = pogoh_df[~pogoh_df[\"end_station_id\"].isnull() & ~pogoh_df[\"end_station_name\"].isnull()].copy()\n",
    "print(pogoh_df.shape)\n",
    "print(pogoh_df_cleaned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb6679e",
   "metadata": {},
   "source": [
    "Now we move to standardizing the names of the stations and checking if the stations IDs map to a unique station. \n",
    "\n",
    "NOTE: There have been instances of POGOH stations being relocated, this might bring some issies. For example, if a station was relocated and the name changed but the ID didn't.\n",
    "\n",
    "For starting stations, all of the ID and names were paired uniquely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ebd179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for start station ID mapping to more than one name\n",
    "start_conflicts = (\n",
    "    pogoh_df_cleaned.groupby(\"start_station_id\")[\"start_station_name\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"name_count\")\n",
    ")\n",
    "start_conflicts = start_conflicts[start_conflicts[\"name_count\"] > 1]\n",
    "\n",
    "pogoh_df_cleaned.groupby(\"start_station_id\")[\"start_station_name\"].nunique()\n",
    "\n",
    "# Display actual name mismatches (if any)\n",
    "if not start_conflicts.empty:\n",
    "    display(\n",
    "        pogoh_df_cleaned[\n",
    "            pogoh_df_cleaned[\"start_station_id\"].isin(start_conflicts[\"start_station_id\"])\n",
    "        ][[\"start_station_id\", \"start_station_name\"]].drop_duplicates().sort_values(\"start_station_id\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e283cd65",
   "metadata": {},
   "source": [
    "For end stations, the ID and name matching also didn't have any issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b34d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_conflicts = (\n",
    "    pogoh_df_cleaned.groupby(\"end_station_id\")[\"end_station_name\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"name_count\")\n",
    ")\n",
    "end_conflicts = end_conflicts[end_conflicts[\"name_count\"] > 1]\n",
    "\n",
    "if not end_conflicts.empty:\n",
    "    display(\n",
    "        pogoh_df_cleaned[\n",
    "            pogoh_df_cleaned[\"end_station_id\"].isin(end_conflicts[\"end_station_id\"])\n",
    "        ][[\"end_station_id\", \"end_station_name\"]].drop_duplicates().sort_values(\"end_station_id\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d8db5a",
   "metadata": {},
   "source": [
    "Just to be safe, I'm also checking that the ID/name pairs are exactly the same between the start and end stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11856dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get unique (station_id, station_name) pairs from start and end columns\n",
    "start_pairs = pogoh_df_cleaned[[\"start_station_id\", \"start_station_name\"]].drop_duplicates()\n",
    "end_pairs = pogoh_df_cleaned[[\"end_station_id\", \"end_station_name\"]].drop_duplicates()\n",
    "\n",
    "# 2. Rename end_pairs to align columns for comparison\n",
    "end_pairs = end_pairs.rename(columns={\n",
    "    \"end_station_id\": \"start_station_id\",\n",
    "    \"end_station_name\": \"start_station_name\"\n",
    "})\n",
    "\n",
    "\n",
    "end_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d9203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Check for pairs that appear in start but not in end\n",
    "start_only = pd.merge(start_pairs, end_pairs, how=\"left\", indicator=True)\n",
    "start_only = start_only[start_only[\"_merge\"] == \"left_only\"].drop(columns=\"_merge\")\n",
    "\n",
    "# 4. Check for pairs that appear in end but not in start\n",
    "end_only = pd.merge(end_pairs, start_pairs, how=\"left\", indicator=True)\n",
    "end_only = end_only[end_only[\"_merge\"] == \"left_only\"].drop(columns=\"_merge\")\n",
    "\n",
    "# 5. Print result summary\n",
    "print(\"Start-only station pairs (not seen in end stations):\", len(start_only))\n",
    "print(\"End-only station pairs (not seen in start stations):\", len(end_only))\n",
    "\n",
    "# 6. (Optional) Display mismatched pairs if needed\n",
    "if not start_only.empty:\n",
    "    print(\"Start-only mismatches:\")\n",
    "    print(start_only)\n",
    "\n",
    "if not end_only.empty:\n",
    "    print(\"End-only mismatches:\")\n",
    "    print(end_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8266f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pogoh_df_cleaned.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pogoh_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
